# Deep_Learning

## O.Reilly의 **밑바닥부터 시작하는 딥러닝** 책을 읽으며 공부

0. Perseptron

1. neural network

2. neural network2(ReLU)

3. neural network implementation

4. array and matrix

5. softmax

6. MNIST

7. neuralnet_MNIST

8. neuralnet_MNIST_batch

9. mean_squared_error

10. cross_entropy_error

11. mini_batch

12. numerical_differential

13. partial_differential

14. gradient

15. gradient_descent

16. gradient_simplenet

17. two_layer_net

18. train_neuralnet

19. backpropagation

20. layer_naive_Multiply

21. layer_naive_Add

22. Layers

23. two_layer_net(backpropagation)

24. gradient_check

25. train_neuralnet(backpropagation)

26. Momentum

27. AdaGrad

28. Adam

29. optimizer_compare_mnist

30. weight_init_activation_histogram

31. weight_init_compare

32. batch_norm_test

33. overfit_weight_decay

34. overfit_dropout

35. hyperparameter_optimization

36. util

37. simple_convnet

38. train_convnet

39. gradient_check2

40. apply_filter

41. visualize_filter

42. half_float_network

__________________________________________

*심층 신경망을 만들어 MNIST 데이터셋의 손글씨 숫자 인식해보기*

**deep_convnet - 신경망 구현** <br>
<li> 가중치 초깃값 : He 초깃값</li>
<li> 가중치 매개변수 : Adam</li>
<li> 활성화 함수 : ReLU</li>
<li> 3 * 3의 작은 필터를 사용한 합성곱 계층</li>

**train_deepnet - 훈련 데이터**

**deep_conv_net_params.pkl - 학습된 가중치 매개변수**

**misclassified_mnist - 잘못 분류된 데이터**


*신경망 정확도 : 99.36%*(매 학습마다 약간씩 달라짐)
